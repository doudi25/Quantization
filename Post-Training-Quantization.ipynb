{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:06:20.233971Z",
     "start_time": "2024-08-16T21:06:15.616895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ],
   "id": "b1b9cd802da668e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:06:20.283144Z",
     "start_time": "2024-08-16T21:06:20.233971Z"
    }
   },
   "cell_type": "code",
   "source": "_ = torch.manual_seed(0)",
   "id": "4aefd6c183330a2e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:06:48.052420Z",
     "start_time": "2024-08-16T21:06:20.284148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
   ],
   "id": "2f7462cec0c76f35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:17<00:00, 576689.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 168035.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:03<00:00, 489884.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:06:48.057268Z",
     "start_time": "2024-08-16T21:06:48.052787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VerySimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
    "        super(VerySimpleNet,self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1) \n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "id": "5a3f0b22cfa9793c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:07:05.891117Z",
     "start_time": "2024-08-16T21:07:05.638668Z"
    }
   },
   "cell_type": "code",
   "source": "net = VerySimpleNet().to(device)\n",
   "id": "f297dac831581b8b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:08:02.557863Z",
     "start_time": "2024-08-16T21:07:18.104816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x.view(-1, 28*28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "            \n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'simplenet_ptq.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(train_loader, net, epochs=1)\n",
    "    # Save the model to disk\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)"
   ],
   "id": "a9a88a36bb9748de",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6000/6000 [00:44<00:00, 135.34it/s, loss=0.223]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:08:12.841465Z",
     "start_time": "2024-08-16T21:08:12.829844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model: nn.Module, total_iterations: int = None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "            iterations += 1\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')"
   ],
   "id": "e2be5bbd4b824f17",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:09:32.596110Z",
     "start_time": "2024-08-16T21:09:32.584663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Size of the model before quantization')\n",
    "print_size_of_model(net)"
   ],
   "id": "194b7108373dc72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB): 361.062\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:10:14.268210Z",
     "start_time": "2024-08-16T21:09:42.152171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Accuracy of the model before quantization: ')\n",
    "test(net)"
   ],
   "id": "259a478d4acb37fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:32<00:00, 31.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:19:35.467616Z",
     "start_time": "2024-08-16T21:19:35.458145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuantizedSimpleNeuralnet(nn.Module):\n",
    "    def __init__(self,hidden_size_1=100,hidden_size_2=100):\n",
    "        super().__init__() \n",
    "        self.quantization = torch.quantization.QuantStub()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1) \n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequantization = torch.quantization.DeQuantStub()\n",
    "    def forward(self,img):\n",
    "        x = img.view(-1,28*28)\n",
    "        x = self.quantization(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequantization(x)\n",
    "        return x\n",
    "\n",
    "        "
   ],
   "id": "c533255269a2cb7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:19:35.716617Z",
     "start_time": "2024-08-16T21:19:35.694460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantized_neural_net = QuantizedSimpleNeuralnet().to(device)\n",
    "quantized_neural_net.load_state_dict(net.state_dict())\n",
    "quantized_neural_net.eval()"
   ],
   "id": "95b5f9091c413f22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedSimpleNeuralnet(\n",
       "  (quantization): QuantStub()\n",
       "  (linear1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (linear2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dequantization): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:19:35.936101Z",
     "start_time": "2024-08-16T21:19:35.861833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add observer on all intermediate layers\n",
    "quantized_neural_net.qconfig = torch.ao.quantization.default_qconfig\n",
    "quantized_neural_net = torch.ao.quantization.prepare(quantized_neural_net)\n",
    "quantized_neural_net"
   ],
   "id": "efc5072a6ff75ec7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedSimpleNeuralnet(\n",
       "  (quantization): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequantization): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:20:11.751479Z",
     "start_time": "2024-08-16T21:19:37.337222Z"
    }
   },
   "cell_type": "code",
   "source": "test(quantized_neural_net)",
   "id": "e882b9f3b7a43691",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:34<00:00, 29.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:21:31.540125Z",
     "start_time": "2024-08-16T21:21:31.522098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Verify the statistics collected when running inference')\n",
    "quantized_neural_net"
   ],
   "id": "75f514b7692c4a98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify the statistics collected when running inference\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedSimpleNeuralnet(\n",
       "  (quantization): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-54.36076736450195, max_val=35.85297393798828)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-25.92667007446289, max_val=27.277904510498047)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-28.495838165283203, max_val=21.301504135131836)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequantization): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:23:14.204602Z",
     "start_time": "2024-08-16T21:23:14.032570Z"
    }
   },
   "cell_type": "code",
   "source": "real_quan_nn = torch.ao.quantization.convert(quantized_neural_net)",
   "id": "73f079da7215d50d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:24:55.626550Z",
     "start_time": "2024-08-16T21:24:55.571283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Original weights of the first linear layer')\n",
    "print(net.linear1.weight)\n",
    "print('Dequantized weights of the first linear layer')\n",
    "print(torch.dequantize(real_quan_nn.linear1.weight()))"
   ],
   "id": "494ab6b1b5e2d23e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights of the first linear layer\n",
      "Parameter containing:\n",
      "tensor([[ 7.4281e-05,  1.9500e-02, -2.9053e-02,  ...,  2.2277e-02,\n",
      "          4.0743e-03,  2.4020e-03],\n",
      "        [-1.5416e-02, -1.0620e-02, -6.0812e-03,  ..., -1.5903e-02,\n",
      "         -1.6012e-03, -2.5585e-02],\n",
      "        [ 2.0023e-02,  5.5070e-02,  6.8960e-03,  ...,  1.9828e-02,\n",
      "          4.1354e-02,  4.8199e-02],\n",
      "        ...,\n",
      "        [ 4.9189e-02,  5.2900e-02,  1.8281e-02,  ...,  1.2918e-02,\n",
      "          3.2172e-02, -4.7868e-03],\n",
      "        [-9.3255e-03, -1.2189e-03,  3.0838e-02,  ...,  1.1121e-02,\n",
      "          1.1175e-02,  1.0678e-02],\n",
      "        [ 1.7474e-02,  1.2149e-02, -2.0101e-03,  ...,  3.4410e-02,\n",
      "         -1.4872e-02,  5.2539e-03]], device='cuda:0', requires_grad=True)\n",
      "Dequantized weights of the first linear layer\n",
      "tensor([[ 0.0000,  0.0185, -0.0278,  ...,  0.0231,  0.0046,  0.0046],\n",
      "        [-0.0139, -0.0093, -0.0046,  ..., -0.0139,  0.0000, -0.0278],\n",
      "        [ 0.0185,  0.0555,  0.0046,  ...,  0.0185,  0.0416,  0.0463],\n",
      "        ...,\n",
      "        [ 0.0509,  0.0509,  0.0185,  ...,  0.0139,  0.0324, -0.0046],\n",
      "        [-0.0093,  0.0000,  0.0324,  ...,  0.0093,  0.0093,  0.0093],\n",
      "        [ 0.0185,  0.0139,  0.0000,  ...,  0.0324, -0.0139,  0.0046]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:31:45.114771Z",
     "start_time": "2024-08-16T21:31:45.108880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'data type of quantized weights')\n",
    "real_quan_nn.linear1.weight().dtype"
   ],
   "id": "1de3d5ef7c521085",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of quantized weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.qint8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T21:29:57.381006Z",
     "start_time": "2024-08-16T21:29:57.370551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('the size of the model after quantization')\n",
    "print_size_of_model(real_quan_nn)\n",
    "# we can see that the model size is reduced by factor of 4 , because we convert from 32 singleprecision floating point to 8 bits integer"
   ],
   "id": "26aa89b578ad43ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the model after quantization\n",
      "Size (KB): 95.458\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
